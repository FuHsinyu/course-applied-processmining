{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Applied Process Mining Module\r\n",
    "\r\n",
    "This notebook is part of an Applied Process Mining module. The collection of notebooks is a *living document* and subject to change. \r\n",
    "\r\n",
    "# Hands-on 4 - 'Predictive Process Mining' (Python / PM4Py)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "<img src=\"https://pm4py.fit.fraunhofer.de/static/assets/images/pm4py-site-logo-padded.png\" alt=\"PM4Py\" style=\"width: 200px;\"/>\n",
    "\n",
    "In this notebook, we are using the following libraries: \n",
    "\n",
    "* [numpy](https://numpy.org/)\n",
    "* [pandas](https://pandas.pydata.org/)\n",
    "* [PM4Py library](https://pm4py.fit.fraunhofer.de/)\n",
    "* [PyTorch](https://pytorch.org/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Perform the commented out commands to install the dependencies\r\n",
    "# %pip install numpy\r\n",
    "# %pip install pandas\r\n",
    "# %pip install matplotlib\r\n",
    "# %pip install pm4py\r\n",
    "# %pip install pytorch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import pm4py\r\n",
    "import os\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Event Log"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sepsis = pd.read_csv(\"../data/sepsis.csv\", sep=';')\r\n",
    "sepsis_log = pm4py.format_dataframe(sepsis, case_id='case_id', activity_key='activity', timestamp_key='timestamp')\r\n",
    "sepsis_log = pm4py.convert_to_event_log(sepsis_log)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(sepsis_log)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Extraction / Encoding\n",
    "\n",
    "We are using the PM4Py functionality here:\n",
    "\n",
    "https://pm4py.fit.fraunhofer.de/documentation/1.5#item-7-0-1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set of Events / 2-grams"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data, feature_names = get_log_representation.get_representation(sepsis_log, \r\n",
    "                                                                str_ev_attr=[\"concept:name\"],\r\n",
    "                                                                str_tr_attr=[],\r\n",
    "                                                                num_ev_attr=[],\r\n",
    "                                                                num_tr_attr=[],\r\n",
    "                                                                str_evsucc_attr=[])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "feature_names"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, PM4Py gives us a *one-hot encoding* of the so called *set abstraction* of the event log. This means there are 16 distinct activities in the event log and the feature vector simply encodes whether that activity is present or not in the data. \n",
    "\n",
    "Let us have a look at the distribution of these feature vectors:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dist_features = np.unique(data, return_counts= True, axis = 0)\n",
    "dist_features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is the most common feature vector?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dist_features[0][np.argmax(dist_features[1])]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Makes sense, almost all activities actually are bound to occur in this process. There are only few choices.\n",
    "So, this encoding is likely not the most useful one but let's anyway try to use it for an initial predictive model and iterate later."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bag of Words / Multiset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(sepsis.loc[:,[\"case_id\"]].nunique())\n",
    "data = np.asarray(sepsis.loc[:,[\"case_id\", \"activity\"]].groupby([\"case_id\", \"activity\"]).size().unstack(fill_value=0))\n",
    "data.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Throughput time"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pm4py.statistics.traces.log import case_statistics\n",
    "durations = np.asarray(case_statistics.get_all_casedurations(sepsis_log, parameters={ case_statistics.Parameters.TIMESTAMP_KEY: \"time:timestamp\"} ))\n",
    "durations = np.expand_dims(durations, 1)\n",
    "len(durations)\n",
    "durations = durations / 60 / 60 / 24"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(durations).boxplot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "data = data.astype('float32')\n",
    "durations = durations.astype('float32')\n",
    "\n",
    "print(data.shape)\n",
    "print(durations.shape)\n",
    "\n",
    "ds = TensorDataset(torch.from_numpy(data), \n",
    "                   torch.from_numpy(durations))\n",
    "train_dataloader = DataLoader(ds, batch_size=64, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's define a simple network and try to overfit:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(            \n",
    "            torch.nn.Linear(16, 512),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            nn.ReLU(),            \n",
    "            torch.nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = 'cpu' #'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train(dataloader, model, loss_fn, measure_fn, optimizer, epochs, print_interval = 10):\n",
    "    \n",
    "    losses = []\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    for epoch in range(epochs):    \n",
    "        \n",
    "        loop = tqdm(dataloader)\n",
    "\n",
    "        for batch, (X, y) in enumerate(loop):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Compute prediction error\n",
    "            pred = model(X)\n",
    "            \n",
    "            loss = loss_fn(pred, y)\n",
    "            measure = measure_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append([loss.item(), measure.item()])\n",
    "\n",
    "            loop.set_description('Epoch {}/{}'.format(epoch + 1, epochs))\n",
    "            loop.set_postfix(loss=loss.item(), measure=measure.item())\n",
    "    \n",
    "    return losses"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "measure_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "results = train(train_dataloader, model, loss_fn, measure_fn, optimizer, 500)\n",
    "print(\"Done!\")"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results_data = pd.DataFrame(results).rolling(window=15).mean()\n",
    "results_data.columns = ['loss', 'measure']\n",
    "ax = results_data.plot(subplots=True);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}